[
  {
    "id": "chunk_0000",
    "text": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "section": "Title",
    "subsection": "Title",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 14,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0001",
    "text": "XAI, Explainability, Visual Interpretability, Pre-Hoc, q-grams, Tweet User Profiling, Tweet Classification, Gram-Weighted Tracing (IGWT), Token Contribution Analysis, Active Learning",
    "section": "Keywords",
    "subsection": "Keywords",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 19,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0002",
    "text": "INFOTEC Centro de Investigación e Innovación en Tecnologías de la Información y Comunicación\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tCircuito Tecnopolo Sur No 112\nFracc. Tecnopolo Pocitos II\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t20313\n\t\t\t\t\t\t\t\t\tAguascalientes\n\t\t\t\t\t\t\t\t\tMéxico\nCIMAV Center for Research in Advanced Materials. Av. Miguel de Cervantes 120 Complejo Industrial\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t31136\n\t\t\t\t\t\t\t\t\tChihuahua\n\t\t\t\t\t\t\t\t\tChih\n\t\t\t\t\t\t\t\t\tMéxico\nINFOTEC Centro de Investigación e Innovación en Tecnologías de la Información y Comunicación\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tCircuito Tecnopolo Sur No 112\nFracc. Tecnopolo Pocitos II\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t20313\n\t\t\t\t\t\t\t\t\tAguascalientes\n\t\t\t\t\t\t\t\t\tMéxico\nConsejo Nacional de Humanidades\n\t\t\t\t\t\t\t\tCiencia y Tecnología (CONAHCYT)\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tInsurgentes Sur 1582\nCrédito Constructor\n\t\t\t\t\t\t\t\tCDMX\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tMéxico\nINFOTEC Centro de Investigación e Innovación en Tecnologías de la Información y Comunicación\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tCircuito Tecnopolo Sur No 112\nFracc. Tecnopolo Pocitos II\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t20313\n\t\t\t\t\t\t\t\t\tAguascalientes\n\t\t\t\t\t\t\t\t\tMéxico\nConsejo Nacional de Humanidades\n\t\t\t\t\t\t\t\tCiencia y Tecnología (CONAHCYT)\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tInsurgentes Sur 1582\nCrédito Constructor\n\t\t\t\t\t\t\t\tCDMX\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tMéxico",
    "section": "Affiliations",
    "subsection": "Affiliations",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 123,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0003",
    "text": "Juan Calderón",
    "section": "Authors",
    "subsection": "Authors",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 2,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0004",
    "text": "José Calderón",
    "section": "First_Author",
    "subsection": "First_Author",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 2,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0005",
    "text": "User profiling and supervised classification of short-texts, such as tweets, face a series of challenges that affect both model performance and explainability in ways that are interpretable to humans, as explained by Zhao et al. \nTo address these issues, a pre-hoc explainability model \nQ-grams facilitating the detection of suffixes, prefixes, variations, and typographical errors while also increase the number of related texts detected by user profiling and classification algorithms, providing significant advantages that enhance the performance of algorithms \nTo address this challenge, our core proposal centers on tracing each q-gram back to its original word, unlocking human-understandable explanations into the model's decision-making process. This tracing mechanism is pivotal: it retains the computational efficiency and predictive power of q-grams while bridging the gap to human understanding. By visually mapping q-gram contributions to their source words, we preserve the performance benefits of subword features and recover the intuitive meaning of full words-enhancing interpretability without compromising robustness. Crucially, visualizing contributions enables human-readable explainability \nThis proposed approach adopts a pre-hoc explainability model, which could also be considered hybrid as it incorporates post-hoc techniques \nThe visual analysis not only enhances the level of explainability regarding the algorithm's decisions but also enables the end-user of the framework to tailor the dataset to their specific objectives, such as correcting undesirable or biased contributions or adapting the dataset to a different region or domain from the original. Moreover, this approach aligns perfectly with active learning strategies \nThe proposed explainability framework relies on the weights of q-grams, enabling the setting of thresholds on the weights to be considered. This feature will be used to demonstrate the feasibility of the proposal by applying different thresholds to the dataset and comparing the results.\nIn summary, this proposal introduces an innovative approach to enhancing the explainability of profiling and classification by explicitly addressing the challenges posed by high dimensionality and the high sparsity inherent in short texts. By leveraging intrinsically interpretable models and techniques for tracing q-gram contributions, it offers an approach that not only facilitates the understanding of model decisions, but also enables the efficient refinement or adaptation of the dataset as required by the researcher.",
    "section": "Introduction",
    "subsection": "Introduction",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 355,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0006",
    "text": "As analyzed in \nIn their experimental analysis \nTo further validate these findings, we conducted a two-stage experiment aimed at assessing the impact of q-gram tokenization in short-text NLP tasks. In the first stage, standard tokenization (without q-grams) was applied to establish a baseline. In the second stage, q-gram tokenization was performed. Fig.",
    "section": "Other",
    "subsection": "Q-grams tokenization",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 52,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0007",
    "text": "Tweets profiling and classification present a challenge due to the high diversity of contents, ambiguity, limited length, and lack of context in these microtexts. These factors exacerbate common issues in NLP, such as typographical errors, regional differences in language use and words out of vocabulary, which reduce the quality of the data for extracting accurate and reliable information \nFig.",
    "section": "Other",
    "subsection": "Challenges in NLP Tasks related to Tweets",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 59,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0008",
    "text": "Moreover, the bag-of-words schemes used for tweets representation often produce feature matrices with high dimensionality and sparsity, leading to a low standard deviation \nThis makes it challenging to identify the most influential tokens and complicates the interpretability of the model \nAs explained in \nHowever, a challenge with all these reduction and selection techniques in high-dimensional spaces is that multiple feature subsets can achieve similar performance metrics \nThese reduction and selection techniques are effective, but they must be applied with extreme caution to avoid compromising explainability.",
    "section": "Other",
    "subsection": "Dimensionality Reduction and Feature Selection Techniques",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 85,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0009",
    "text": "At the same time, recent studies \nNumerous studies highlight the importance of explainability in building reliable and transparent models \nVisualization techniques, such as heatmaps and bar charts, are useful for analyzing global patterns \nHowever, although these techniques can provide a global understanding of the data, they are not sufficient to offer clear and detailed explanations for specific predictions in high-dimensional spaces.",
    "section": "Other",
    "subsection": "Visual Explainability in High-Dimensional Spaces",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 61,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0010",
    "text": "With the rapid rise of Artificial Intelligence (AI) in various domains, the need for explainability in AI models has become increasingly important \nTo address the challenge of understanding decisions, tools like Local Interpretable Model-agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP) were developed. These tools have gained widespread recognition for their ability to offer both global and local explanations of model predictions. LIME works by creating local surrogate models around a prediction, helping to explain individual outcomes by approximating the decision boundary in the vicinity of the instance. SHAP, based on cooperative game theory, attributes a Shapley value to each feature, indicating its contribution to the prediction, making it valuable for understanding feature importance both globally and for individual predictions \nHowever, despite the success of explainability tools like SHAP and LIME, they encounter significant challenges in high-dimensional, large-scale, and sparse/low-density environments. Their algorithms, while powerful, are computationally intensive, becoming increasingly expensive, and their performance degrades as the number of features grows. Moreover, the complexity of visually representing a vast number of features complicates the task of providing clear and interpretable results. These two issues highlight the need for more optimized or hybrid solutions that can handle the demands of high-dimensional data without compromising visual explainability \nFor instance, in the case of a simple tweet such as \"#masterchefmx y salen los putos a tener fantasías con el chef irlandés\", a vector with 201 q-grams is generated. Among these, only 9 correspond to complete and readable words, such as 'chef', 'fantasías', and 'irlandeses'. The remaining 192 q-grams, however, consist of fragmented sequences like '#m', 'alen', 'a', and 'con', which are difficult to interpret in humanreadable terms.\nFigure \nThis challenge escalates exponentially in user profiling tasks, where tweets from a single user must be grouped based on author-related similarities. In such cases, grouped tweets often produce over 25,000 q-grams, making their visualization through SHAP virtually impossible as shown in figure",
    "section": "Other",
    "subsection": "Explainability in Artificial Intelligence",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 317,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0011",
    "text": "Explainability can be implemented through different approaches \nOn the other hand, post-hoc strategies are applied after the model has been trained, especially for complex and difficult-to-interpret models (such as neural networks). These techniques generate explanations without modifying the model's structure. Post-hoc models can use surrogate models, which are interpretable models designed to approximate the behavior of a complex model. For example, LIME trains a linear surrogate model around a specific prediction, allowing it to identify which features most influence that local prediction. However, the downside of surrogate models is that they are approximations, meaning they may not fully capture the complexity of the original model or may oversimplify it.\nLastly, hybrid strategies combine pre-hoc techniques, which ensure explainability from the start, with post-hoc techniques that provide more detailed explanations \nAligned with combined explainability strategies, we propose a pre-hoc approach that leverages a linear model during the preprocessing stage, independent of the target model intended for use. By using interpretable coefficients, this approach facilitates the identification of biases, problematic patterns, and anomalies in the dataset. Also, it allows researchers to refine the dataset to suit specific objectives, such as adapting it to a different domain or aligning it with particular research goals. This flexibility ensures that the dataset is both optimized and tailored to meet the requirements of the task at hand.\nAdditionally, this approach is well-suited for Active Learning cycles \nIn summary, while traditional visualization techniques and dimensionality reduction methods are useful for general analysis, and tools like LIME and SHAP enhance local interpretability, there remains a need to strike a balance between dimensionality reduction and explainability in order to achieve models that are both effective and interpretable in the context of short-text tasks, such as tweets profiling and classification.",
    "section": "Other",
    "subsection": "Pre-hoc and Post-hoc Explainability Strategies",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 290,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0012",
    "text": "In this proposal, we chose q-gram tokenization \nAlthough transformers, like Bidirectional Encoder Representations from Transformers (BERT) \nFurthermore, this proposal seeks to develop an explainability framework focused on active learning, where q-grams and linear classifiers enable an iterative analysis of data beyond the reach of modern classifiers such as those based in embeddings and transformers. This pre-hoc approach optimizes the dataset in the early stages of processing, improving the efficiency and quality of any target model.",
    "section": "Other",
    "subsection": "Embedding Schemes and Transformers",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 75,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0013",
    "text": "Building upon the challenges and preliminary solutions outlined in 2 (State of the Art), this proposal introduces IGWT, a visual explanatory framework specifically designed to address the high-dimensional and sparse nature of tweet data. At its core, IGWT integrates q-gram tracing with linear models, applied during the preprocessing phase to tailor the dataset to task-specific requirements via an active learning cycle.\nTo enhance visual interpretability, we compute the contribution of each q-gram and then trace the most relevant ones back to their original words. This mapped traceability enables a human-readable association between influential q-grams and the lexical units they originate from. For instance, the word intelligent produces q-grams (q=3 ) such as [' in', 'int', 'nte', ..., 'ent', 'nt ' ]. By mapping these q-grams back to the word, we enhance interpretability by allowing a direct association between the extracted features and their linguistic context. In addition, this approach enhances explainability without compromising the performance advantages of q-grams-namely, their ability to capture morphological variation and handle out-of-vocabulary terms effectively.\nFigure \nThis explainability mechanism is primarily pre-hoc, as it is applied before training the target model, to analyze and optimize the dataset at an early stage. Nevertheless, by employing a surrogate model-typically associated with post-hoc techniques-during preprocessing, this approach combines the benefits of both paradigms.",
    "section": "Methods",
    "subsection": "Our Approach",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 214,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0014",
    "text": "Our research leverages the vast number of datasets available for tweet analysis tasks, forums and competitions, with Iberian Languages Evaluation Forum (IberLEF) and Conference and Labs of the Evaluation Forum (CLEF) being among the most notable sources. These datasets offer the advantage of being precleaned, structured, and labeled, which facilitates tasks such as supervised classification. However, depending on the dataset and task, additional preprocessing may be required. Traditional techniques-such as stopword removal, lowercasing, and punctuation filtering-are applied when necessary to improve data quality and model performance.\nIn user profiling tasks, for example, a clustering step using the K-Means algorithm was performed to group tweets by user, enabling profile-level classification. To enhance the effectiveness of this process, standard preprocessing techniques were applied prior to clustering, helping reduce noise and improve the coherence of the resulting user groups.",
    "section": "Other",
    "subsection": "Datasets",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 136,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0015",
    "text": "Once the datasets have been selected, the next step is to transform the text into a vector space supported by the BoW schemes, ensuring that the transformation process includes the fragmentation of words into q-grams. For this transformation, we have chosen the µTC framework \nAmong its advanced tokenization capabilities, µTC allows for and controls the decomposition of words into q-gram sequences ranging from 1 to 5 characters, which not only improves prediction accuracy but also serves as the foundation for implementing explainability at the subword level. While µTC facilitates this advanced tokenization, the traceability of each q-gram back to its original word -a core objective of our proposal-is achieved through additional methods built on top of the decomposition performed by µTC.",
    "section": "Other",
    "subsection": "Text Transformation with Micro Text Classifier (µTC)",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 121,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0016",
    "text": "As reviewed, feature engineering techniques are essential for reducing and optimizing vector spaces used by NLP algorithms. For user profiling and supervised classification of tweets, our proposal has selected methods that take into account the assigned label and perform well in high-dimensional spaces, such as mutual information and chi-square. In our approach, we apply these techniques to exclude non-significant tokens in a massive, quick, and computationally inexpensive way, streamlining the process. Although this filtering step alone may not significantly reduce dimensionality in all cases, its very low computational cost and minimal impact on interpretability justify its application.",
    "section": "Other",
    "subsection": "Dimensionality Reduction and Feature Selection",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 97,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0017",
    "text": "In general terms, training a linear classifier for binary classification involves finding a hyperplane that separates the two classes in the feature space (for multiclass classification, this could becomes a one-vsrest problem). For a new instance, the decision function is a linear combination of the features weighted by their respective coefficients, which determines on which side of the hyperplane it lies and, therefore, to which class it belongs. Specifically, Linear Support Vector Classification (LinearSVC) \nLinearSVC is suitable for classification problems where the classes are linearly separable and handles high dimensionality well, making it ideal for supervised classification of tweets, and consequently, for our proposal. LinearSVC enhances interpretability by assigning coefficients to each token, revealing the degree of its contribution to the classification outcome.\nFurthermore, the selection of LinearSVC was based on specific criteria, as it meets other functionalities sought in this proposal: i) the calculation of coefficients and the decision function are integrated into the algorithm, so no additional computations are required; ii) it supports l1 regularization (Lasso), which reduces small coefficients to zero and automatically removes features below a set threshold; iii) it integrates easily into the preprocessing phase; and iv) it is independent of the target model chosen for user profiling or classification.\nIn this way, by combining the explanatory properties of LinearSVC with the traceability of q-grams back to their original words in the tweet, our approach enhances the granularity of visual interpretability for each tweet in the dataset. This allows the proposed IGWT framework to facilitate, in humanunderstandable terms, the identification of misclassified or mislabeled instances, defective tokens, biases and any other insight at the individual instance level, while also providing valuable insights into the model's global behavior.",
    "section": "Other",
    "subsection": "Integration of an Interpretable Linear Model (LinearSVC)",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 282,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0018",
    "text": "As part of the innovation and practical application of the proposed IGWT framework, an interactive website has been developed that allows researchers to upload and analyze datasets of tweets for user profiling tasks, supervised classification, or related tasks. This platform displays the results directly on screen, facilitating a detailed and visual analysis of each tweet with its predicted and pre-labeled classification.\nThe framework organizes and presents the data in a multi-level structure, including details such as the decision function, true and predicted classes, and the q-grams, visualized their importance using heat-maps. Researchers can dynamically adjust parameters such as threshold for the decision function and threshold for the weight to optimize visualization and results. This data structure is highly reusable for various additional procedures, including, for instance, the implementation of embedding techniques to explore relationships between the q-grams. This opens a wide spectrum of possibilities and allows for adapting and expanding the analysis to a variety of advanced approaches in natural language processing and machine learning.\nThe site also serves as an ideal platform for active learning, allowing users to make iterative adjustments, observe how these impact explainability in NLP tasks almost in real time, and continuously refine the model according to their specific research needs. This capability for iteration and adjustment turns the website into a powerful tool for experimentation and optimization of the dataset prior to the final training of tweets, thereby improving the understanding, accuracy, and interpretability of the target model.\nThe IGWT framework is designed for researchers with a good understanding of the dataset's domain and the target model, ensuring that any experimentation aligns with both the dataset's characteristics and the model's objectives. A screenshot of the interface is provided in Appendix B to illustrate how tokens and q-gram contributions are visually presented in practice, showcasing the interpretability features available in the interactive environment.",
    "section": "Other",
    "subsection": "Interactive Web-Based Framework",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 307,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0019",
    "text": "Algorithm 1 presents the interpretability workflow proposed for tweet analysis. Its purpose is to enable a visual and interpretable understanding of how each lexical unit (token or word) contributes to the model's predictions, by aggregating the individual contributions of its constituent q-grams. This understanding is both quantitative-since it is based on the weighted contributions assigned to each q-gram-and qualitative, as the tracing mechanism links these subword units back to their original linguistic context. As a result, researchers can identify and mitigate potential biases, detect mislabeled data, and extract critical insights prior to applying the target model to the dataset. Store predicted class, score, token contributions, and q-gram-word mappings; Save as hierarchical dictionary (see Appendix) Step 9: Visualize Results Render heatmap contributions of tokens and q-grams; Display original words with their associated influence This algorithmic facilitates efficient data analysis and enables quick access to adjust or validate interpretation outcomes. Besides, the stored structure (JSON format) is also adaptable for future research, as the data is organized and readily accessible.",
    "section": "Other",
    "subsection": "Algorithm -Token-Level Interpretability via Q-Gram Tracing",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 168,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0020",
    "text": "In this section, we evaluate the effectiveness of the proposed IGWT framework. Emphasizing that the strength of IGWT lies in its ability to utilize the coefficients of the linear estimator to maintain competitive performance in models, while also leveraging and combining the traceability of q-grams to their original words to provide efficient visual aids that enhance the explainability of decisions. Additionally, it is important to highlight that IGWT can process a large number of instances simultaneously, further increasing the identification of the most influential words and q-grams and, consequently, its explanatory capacity. All of this is focused on addressing the challenges of high dimensionality and high dispersion generated by short-text in NLP tasks, such as user profiling in tweets.",
    "section": "Results",
    "subsection": "Experimental Results",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 119,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0021",
    "text": "Fig. \nGiven its color intensity, it is observed that tokens like estupida and mierda have a high contribution to the offensive class, while altere contributes negatively. Words such as perdón do not meet the relevance Fig. \nThe decision function value indicates that the tweet is offensive. A green table breaks down the n most influential q-grams, including those corresponding to complete words, such as gente and mierda. This explainability exercise is complemented by specific tables that highlight how q-grams, even with a higher contribution than certain tokens, influence the classification, providing greater transparency in the model.\nJust as figure \nIt is important to emphasize that figures 3 and 4 present only a fragment of the visualization for a single instance of their respective tasks and datasets. However, unlike other interpretability tools that are focused to global explanations or single-instance interpretation with a small number of features, the proposed framework is capable of displaying all instances in the dataset under examination, as shown in appendix B. Additionally, the significance level of the highlighted tokens is controlled by a threshold parameter applied to the coefficients to be considered, while the number of instances displayed is regulated by a decision function threshold parameter.",
    "section": "Other",
    "subsection": "Explainability Example of a Tweet",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 200,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0022",
    "text": "Motivation and Conceptual Basis: Figure \nLimitations of the Traceability Mechanism: Before detailing the experiment, it is important to clarify that the traceability mechanism is constrained to aggregating q-grams that are strictly contained within the boundaries of a given word. It does not incorporate other linguistic properties of q-grams, such as their ability to span across word boundaries or include skip-grams. While this restriction preserves a clear and interpretable mapping between q-grams and lexical units-essential for visual explainability-it may omit contextual or structural patterns that inter-word or skip-based q-grams could capture. Investigating the incorporation of such extensions without compromising interpretability or computational efficiency remains an open direction for future research.\nExperimental Objective and Hypothesis: The goal of the experiment is to evaluate whether qgram traceability improves token-level interpretability by enhancing the measured importance of words within text classification models. The central hypothesis is that mapping q-grams to their original words provides greater explanatory value than relying solely on word-level representations. Specifically, it is hypothesized that the aggregate weight of q-grams corresponding to a given word will exceed the weight assigned to that word when treated as a single unit.\nExperimental Setup: The experiment uses a labeled dataset of tweets encompassing diverse themes and text structures to ensure robustness. The preprocessing phase includes two tokenization scenarios:\n1. Scenario 1: Tokenization is performed using full words. 2. Scenario 2: Tokenization is performed using character-level bi-grams, tri-grams, and quad-grams extracted as subword units within each word.\nThis design allows for a direct comparison between traditional word-based representations and subwordbased representations using q-grams, enabling an evaluation of their respective effects on model interpretability.\nModeling and Feature Representation: In both scenarios, TF-IDF is used to vectorize the input data. A linear classifier (LinearSVC) is trained independently on each representation. In Scenario1, model coefficients are assigned to full words; in Scenario2, coefficients are assigned to q-grams.\nAggregation via Traceability: To enable comparison, the traceability mechanism links each word from Scenario1 to its constituent q-grams in Scenario2. The contribution of a word in Scenario 2 is computed by summing the weights (model coefficients) of all q-grams derived from that word. This aggregation allows for a fair comparison of token-level importance across the two representations.\nWeight Comparison and Statistical Analysis: A paired t-test is conducted to compare the weights of words in both scenarios. The test assesses whether the aggregated q-gram weights in Scenario2 are significantly greater than the corresponding word-level weights in Scenario1. Metrics such as the mean difference, standard deviation, and p-value are calculated to evaluate statistical significance.\nResults and Visualization: Figure",
    "section": "Results",
    "subsection": "Experimental Evaluation of Q-Gram Traceability for Token-Level Interpretability",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 425,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0023",
    "text": "This experiment provides quantitative evidence that the traceability of q-grams to their original words improves both the measured importance and interpretability of lexical units in text classification models. By enabling the aggregation of subword contributions, the model can better recognize and explain the influence of individual terms-particularly in short-text NLP tasks where sparsity and variability are prevalent. These findings validate the effectiveness of the proposed traceability mechanism as a pre-hoc interpretability strategy.",
    "section": "Conclusion",
    "subsection": "Conclusion:",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 72,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0024",
    "text": "Post-hoc interpretability techniques such as SHAP and LIME have become standard tools for analyzing the decision-making process of complex models. However, these approaches introduce limitations when applied to high-dimensional and sparse textual data-particularly in the context of short-text classification, such as tweet analysis.\nIn contrast, the proposed interpretability workflow (Algorithm 1) offers several advantages by integrating explainability directly into the data representation and modeling pipeline. While SHAP and LIME provide general-purpose, model-agnostic interpretability, they often struggle with short texts due to their reliance on perturbation-based sampling, which becomes unreliable in high-dimensional, sparse feature spaces. Furthermore, visualizing thousands of q-grams generated from grouped tweets (e.g., in user profiling tasks) becomes computationally prohibitive under post-hoc frameworks.\nIn contrast, our approach leverages the strengths of linear models to compute exact token contributions, and introduces a q-gram tracing mechanism that maps subword units back to original words. This not only improves interpretability but also enables a human-readable, context-aware explanation of model behavior-before training the target model-making it suitable for both data exploration and bias correction.",
    "section": "Methods",
    "subsection": "Comparison with Post-Hoc Interpretability Methods",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 171,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0025",
    "text": "The IGWT explainability model is structured around four key aspects: (1) the fragmentation of words into q-grams as subword units, (2) the computation of individual q-gram weights, (3) the traceability of these q-grams back to their original words, and (4) the visualization of their aggregated contributions to the model's decision through color-coded heatmaps.\nIn addition, it is computationally efficient, leveraging the coefficients of the self-interpretable linear model. These characteristics allow IGWT to not only enhance explainability but also make it suitable for Active Learning applications, where the model iteratively refines its understanding by analyzing the most informative tokens and instances.\nThe following sections provide a structured overview of the potential uses of the IGWT highlighting its versatility, advantages, and applications in the fields of Machine Learning (ML) and NLP on tasks related to short-text, as well as its impact on both research and practical implementations.\nEfficient Uncertainty Sampling in Active Learning: IGWT enables the rapid detection of instances where the model exhibits high uncertainty or ambiguity, such as in reviews with contradictory terms (e.g., positive and negative words in the same sentence). This facilitates the application of sampling strategies, such as Least Confidence Sampling or Margin Sampling, to prioritize the manual annotation of these cases and focus on the most informative data. Additionally, its low computational cost allows for frequent model retraining, agile incorporation of new instances, and continuous refinement of the model without incurring high computational expenses.\nData Selection with Explainability and Error Analysis: The traceability of q-grams and the heatmaps generated by IGWT make the contributions of words in the model's decisions highly interpretable. This helps experts to:\n-Select samples where the model makes errors or overemphasizes irrelevant words.\n-Identify patterns in misclassified instances, exposing words that disproportionately contribute to errors related to tokenization or data preprocessing. -Detect and correct ambiguous instances (hard-negatives), improving model performance and increasing its robustness. For example, in fake news detection, IGWT identifies articles that appear trustworthy but contain misleading terms.\nBias and Unexpected Pattern Detection: IGWT shows words that excessively influence predictions, exposing potential biases in the model. This serves as a guide to:\n-Avoid unfair or unbalanced decisions, contributing to the creation of fairer and more ethical models.\n-Detect biases toward certain names or terms in hiring tools.\n-Identify unexpected patterns that may indicate issues in the dataset or the model.",
    "section": "Other",
    "subsection": "Applications of IGWT: Enhancing Active Learning and Computational Efficiency",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 390,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0026",
    "text": "Optimization: IGWT analyzes heatmaps across different datasets to identify key linguistic changes and adjust weights in domain-specific terminology. This ensures that transferred models maintain their accuracy in new contexts. For example:\n-A legal text classifier can be adapted from U.S. to European documents.\n-In medicine, IGWT identifies technical terms crucial for accurate diagnoses, allowing experts to fine-tune the model according to the specific needs of the domain.\nIntelligent Data Augmentation and Rapid Interpretability: IGWT uses heatmaps to identify key words and generate new synthetic training samples. These samples retain the most influential words while introducing variations, improving the diversity and representativeness of the dataset. For example, in sentiment analysis, IGWT generates new reviews using synonyms of key words such as amazing or fantastic. Additionally, its ability to generate heatmaps and decision explanations quickly and efficiently reduces the time required for model-based decision-making without sacrificing precision.",
    "section": "Other",
    "subsection": "Domain Adaptation and Model",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 145,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0027",
    "text": "As demonstrated through its potential applications, the impact of the IGWT framework extends beyond interpretability into practical improvements in model development workflows. The IGWT framework supports early detection of low-quality samples, facilitates uncertainty sampling, and guides data refinement-key aspects in active learning strategies. Its linear structure and low computational overhead further enable efficient processing in large-scale or resource-constrained NLP tasks. These properties position IGWT not only as an interpretability tool, but also as a lightweight, datacentric component that enhances learning efficiency and model robustness.",
    "section": "Conclusion",
    "subsection": "Conclusion:",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 84,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0028",
    "text": "The experimental findings validate the core premise of the IGWT framework: that q-gram traceability significantly enhances both the visual and quantitative interpretability of short-text classification models. By decomposing tokens into subword units, assigning individual weights via a linear estimator, and reaggregating them into their original lexical units, IGWT offers a unique pre-hoc interpretability mechanism that maintains model transparency without compromising computational efficiency. As visualized in Figure \nAdditionally, Section 4.4 outlines the broader impact of IGWT beyond static interpretability. The framework's ability to operate efficiently across multiple instances, identify influential or problematic tokens, and guide data refinement positions it as a valuable asset in active learning workflows. Unlike posthoc methods, which struggle with high-dimensional feature spaces and incur significant computational costs, IGWT integrates interpretability directly into the modeling workflow. This integration enables tasks such as uncertainty sampling, error analysis, bias detection, and domain adaptation to be addressed from within the framework itself-facilitating more informed model development.\nIn summary, the IGWT framework not only achieves its original goal of improving visual interpretability in NLP tasks involving short-text but also establishes itself as a lightweight, scalable, and adaptable tool. Its pre-hoc design, grounded in traceable subword features and interpretable linear modeling, makes it especially suited for real-world NLP scenarios where transparency, efficiency, and iterative refinement are essential.",
    "section": "Discussion",
    "subsection": "Discussion of Results and Conclusion",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 214,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0029",
    "text": "While the IGWT framework has shown promising results in enhancing interpretability and supporting active learning strategies, several directions remain open for future exploration.\nFirst, further research is needed to assess the impact of q-gram traceability on downstream NLP tasks performance, particularly in terms of accuracy, f1-score, and robustness across imbalanced or noisy datasets. A systematic evaluation would help quantify the trade-offs between interpretability and predictive power.\nSecond, expanding the traceability mechanism to account for filtered or removed tokens would improve the framework's applicability in data cleaning and preprocessing workflows. This would require integrating information about the role of absent features in the model's decision-making process-an aspect typically overlooked in current approaches.\nThird, while the current implementation is designed for linear models due to their interpretability and efficiency, adapting IGWT to work with neural architectures (e.g., CNNs or transformers) could allow for broader applicability in more complex NLP tasks. This adaptation would involve developing surrogate mechanisms to extract token-level contributions from non-linear decision boundaries.\nFinally, future work could explore additional properties of q-grams, such as cross-token spans and skip-grams, to capture richer morphological or contextual patterns. Incorporating these features in a controlled and explainable manner could further enhance the model's ability to handle lexical variability without sacrificing interpretability or computational efficiency.",
    "section": "Future_Work",
    "subsection": "Future Work",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 210,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0030",
    "text": "The source codes for the Interpretability by Gram-Weighted Tracing (IGWT) framework, along with reproducible experiments, are publicly available in the GitHub repository at: Not yet...",
    "section": "Other",
    "subsection": "Availability of Resources",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 25,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0031",
    "text": "The first author thanks to MSc Rodrigo Dominguez and Professor Jacques Savoy for their invaluable comments and suggestions.\nA Appendix: Example of JSON Structure Generated by the IGWT Basic and trimmed example of an instance from a German tweet dataset.\n{ \"101\": { \"prediction_klass\": \"1\", \"decision_value\": \"0.6579841325\", \"true_klass\": \"1\", \"data\": { \"restaurants\": { \"weight\": 0.7325947434, \"grams\": { \"q:rest\": 0.0358046721, \"q:taur\": 0.0487939050 }, \"color\": \"#FF0000\" }, \"groningen\": { \"weight\": 0.0179637958, \"grams\": { \"q:inge\": 0.0212614873, \"q:gro\": 0.0107364526 }, \"color\": \"#FFC6C6\" } } } }",
    "section": "Other",
    "subsection": "Acknowledgements",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 82,
    "date": "2025-07-01"
  },
  {
    "id": "chunk_0032",
    "text": "The instance \"101\" represents a classification prediction with:\n-Instance \"101\":\n• prediction klass: The predicted class by the model is \"1\".\n• decision value: The decision value calculated for this instance is \"0.6579841325\", indicating the confidence level in the prediction. • true klass: The actual class of the tweet is \"1\", useful for comparative evaluation.\n-data (Details at the word and q-gram level):\n• Word \"restaurants\": * weight: Total weight of the word is 0.7325947434, representing its contribution to the decision function. * grams:\n• q:rest: Contributes a weight of 0.0358046721.\n• q:taur: Contributes a weight of 0.0487939050. * color: Assigned color is #FF0000, which reflects the predicted class, with the intensity indicating the magnitude of the contribution to the prediction, facilitating interpretive visualization on the web interface. • Word \"#groningen\":\n* weight: Total weight of the word is 0.0179637958, representing its contribution to the decision function. * grams:\n• q:inge: Contributes a weight of 0.0212614873.\n• q:gro: Contributes a weight of 0.0107364526. * color: Assigned color is #FFC6C6, used to facilitate interpretive visualization on the web interface.",
    "section": "Other",
    "subsection": "Explanation of the Example:",
    "type": "paper",
    "title": "Improving Visual Interpretability in NLP Short-Text Tasks: A Pre-Hoc Approach Based on Gram-Weighted Tracing",
    "student_id": "ST12345",
    "student_name": "Juan Calderón",
    "document_id": "PAPER2024-001",
    "source_file": "paper1.pdf",
    "language": "en",
    "tokens": 178,
    "date": "2025-07-01"
  }
]